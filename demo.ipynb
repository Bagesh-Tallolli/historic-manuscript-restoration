{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Sanskrit Manuscript Restoration & Translation Demo\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the complete pipeline for processing Sanskrit manuscripts:\\n\",\n",
    "    \"1. Image Restoration (ViT)\\n\",\n",
    "    \"2. OCR (Tesseract/TrOCR)\\n\",\n",
    "    \"3. Unicode Normalization\\n\",\n",
    "    \"4. Sanskrit → English Translation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import our pipeline\\n\",\n",
    "    \"from main import ManuscriptPipeline\\n\",\n",
    "    \"from utils.visualization import visualize_pipeline_stages, create_demo_figure\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"PyTorch version: {torch.__version__}\\\")\\n\",\n",
    "    \"print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Initialize the Pipeline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize pipeline\\n\",\n",
    "    \"# Note: Set restoration_model_path to your trained model if available\\n\",\n",
    "    \"pipeline = ManuscriptPipeline(\\n\",\n",
    "    \"    restoration_model_path=None,  # or 'checkpoints/best_psnr.pth'\\n\",\n",
    "    \"    ocr_engine='tesseract',\\n\",\n",
    "    \"    translation_method='google',\\n\",\n",
    "    \"    device='auto'\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Process a Manuscript Image\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Path to your manuscript image\\n\",\n",
    "    \"image_path = 'data/datasets/samples/sample_manuscript.png'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Process the manuscript\\n\",\n",
    "    \"results = pipeline.process_manuscript(\\n\",\n",
    "    \"    image_path=image_path,\\n\",\n",
    "    \"    save_output=True,\\n\",\n",
    "    \"    output_dir='output'\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Visualize Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display original vs restored\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(14, 7))\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].imshow(results['original_image'])\\n\",\n",
    "    \"axes[0].set_title('Original Manuscript', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"axes[0].axis('off')\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].imshow(results['restored_image'])\\n\",\n",
    "    \"axes[1].set_title('Restored Manuscript', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"axes[1].axis('off')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. View Extracted Text\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print(\\\"EXTRACTED TEXT\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nRaw OCR Output:\\\")\\n\",\n",
    "    \"print(results['ocr_text_raw'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nCleaned Devanagari:\\\")\\n\",\n",
    "    \"print(results['ocr_text_cleaned'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nRomanized (IAST):\\\")\\n\",\n",
    "    \"print(results['romanized'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nWord Count:\\\", results['word_count'])\\n\",\n",
    "    \"print(\\\"Sentences:\\\", len(results['sentences']))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. View Translation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print(\\\"ENGLISH TRANSLATION\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print()\\n\",\n",
    "    \"print(results['translation'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Complete Pipeline Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comprehensive visualization\\n\",\n",
    "    \"visualize_pipeline_stages(results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Test Individual Components\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test OCR only\\n\",\n",
    "    \"from ocr.run_ocr import SanskritOCR\\n\",\n",
    "    \"\\n\",\n",
    "    \"ocr = SanskritOCR(engine='tesseract')\\n\",\n",
    "    \"text = ocr.extract_text(image_path, preprocess=True, lang='san')\\n\",\n",
    "    \"print(\\\"OCR Output:\\\", text)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test Unicode normalization\\n\",\n",
    "    \"from nlp.unicode_normalizer import SanskritTextProcessor\\n\",\n",
    "    \"\\n\",\n",
    "    \"processor = SanskritTextProcessor()\\n\",\n",
    "    \"sample_text = \\\"rāmaḥ vanam gacchati\\\"  # IAST romanization\\n\",\n",
    "    \"result = processor.process_ocr_output(sample_text, input_format='iast')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Input (IAST):\\\", sample_text)\\n\",\n",
    "    \"print(\\\"Devanagari:\\\", result['normalized'])\\n\",\n",
    "    \"print(\\\"Words:\\\", result['words'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test translation\\n\",\n",
    "    \"from nlp.translation import SanskritTranslator\\n\",\n",
    "    \"\\n\",\n",
    "    \"translator = SanskritTranslator(method='google')\\n\",\n",
    "    \"sanskrit_text = \\\"रामः वनं गच्छति\\\"\\n\",\n",
    "    \"english = translator.translate(sanskrit_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Sanskrit:\\\", sanskrit_text)\\n\",\n",
    "    \"print(\\\"English:\\\", english)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Batch Processing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Process multiple manuscripts\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"manuscript_dir = Path('data/raw')\\n\",\n",
    "    \"image_files = list(manuscript_dir.glob('*.jpg')) + list(manuscript_dir.glob('*.png'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Found {len(image_files)} images\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(image_files) > 0:\\n\",\n",
    "    \"    for img_path in image_files[:3]:  # Process first 3\\n\",\n",
    "    \"        print(f\\\"\\\\nProcessing {img_path.name}...\\\")\\n\",\n",
    "    \"        result = pipeline.process_manuscript(img_path, save_output=True)\\n\",\n",
    "    \"        print(f\\\"Translation: {result['translation'][:100]}...\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Export Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Export to various formats\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create summary DataFrame\\n\",\n",
    "    \"summary = {\\n\",\n",
    "    \"    'Image': results['image_path'],\\n\",\n",
    "    \"    'Sanskrit': results['ocr_text_cleaned'],\\n\",\n",
    "    \"    'Romanized': results['romanized'],\\n\",\n",
    "    \"    'English': results['translation'],\\n\",\n",
    "    \"    'Word Count': results['word_count'],\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = pd.DataFrame([summary])\\n\",\n",
    "    \"print(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save to CSV\\n\",\n",
    "    \"df.to_csv('output/results_summary.csv', index=False, encoding='utf-8-sig')\\n\",\n",
    "    \"print(\\\"\\\\n✓ Saved to output/results_summary.csv\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Model Training (if needed)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Example: Train restoration model\\n\",\n",
    "    \"# Uncomment to train\\n\",\n",
    "    \"\\n\",\n",
    "    \"# from train import Trainer\\n\",\n",
    "    \"# from models.vit_restorer import create_vit_restorer\\n\",\n",
    "    \"# from utils.dataset_loader import create_dataloaders\\n\",\n",
    "    \"\\n\",\n",
    "    \"# # Create model\\n\",\n",
    "    \"# model = create_vit_restorer('base', img_size=256)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# # Create dataloaders\\n\",\n",
    "    \"# train_loader, val_loader = create_dataloaders(\\n\",\n",
    "    \"#     train_dir='data/raw',\\n\",\n",
    "    \"#     val_dir=None,\\n\",\n",
    "    \"#     batch_size=8,\\n\",\n",
    "    \"#     img_size=256\\n\",\n",
    "    \"# )\\n\",\n",
    "    \"\\n\",\n",
    "    \"# # Create trainer\\n\",\n",
    "    \"# trainer = Trainer(\\n\",\n",
    "    \"#     model=model,\\n\",\n",
    "    \"#     train_loader=train_loader,\\n\",\n",
    "    \"#     val_loader=val_loader,\\n\",\n",
    "    \"#     device='cuda',\\n\",\n",
    "    \"#     checkpoint_dir='checkpoints'\\n\",\n",
    "    \"# )\\n\",\n",
    "    \"\\n\",\n",
    "    \"# # Train\\n\",\n",
    "    \"# trainer.train(num_epochs=10, save_every=2)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the complete Sanskrit manuscript processing pipeline. You can:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Restore degraded manuscript images\\n\",\n",
    "    \"2. Extract text using OCR\\n\",\n",
    "    \"3. Normalize Unicode Devanagari\\n\",\n",
    "    \"4. Translate to English\\n\",\n",
    "    \"\\n\",\n",
    "    \"For production use, train the ViT restoration model on your specific manuscript dataset for best results.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n",
    "\n"
   ],
   "id": "b029b9bf6876ced5"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
