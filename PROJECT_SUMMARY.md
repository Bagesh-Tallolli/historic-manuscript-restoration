# ğŸ•‰ï¸ Sanskrit Manuscript Restoration & Translation Pipeline

## ğŸ“‹ Project Overview

Complete end-to-end system for processing ancient Sanskrit manuscripts:
- **Image Restoration** using Vision Transformer (ViT)
- **OCR** using Tesseract/TrOCR for Devanagari text extraction
- **Unicode Normalization** for text cleaning and standardization
- **Translation** from Sanskrit to English

---

## âœ… Complete Feature List

### 1. Image Restoration (ViT-based)
- âœ… Full Vision Transformer architecture
- âœ… Patch embedding with configurable patch size
- âœ… Multi-head self-attention mechanism
- âœ… Skip connections for detail preservation
- âœ… Combined L1 + Perceptual loss
- âœ… Support for tiny/small/base/large model sizes
- âœ… Synthetic degradation for training without paired data

### 2. OCR Pipeline
- âœ… Tesseract OCR with Sanskrit/Devanagari support
- âœ… TrOCR (Transformer OCR) support
- âœ… Ensemble OCR combining multiple engines
- âœ… Advanced preprocessing:
  - Grayscale conversion
  - Denoising (non-local means)
  - Deskewing
  - Binarization (Otsu, Adaptive, Sauvola)
  - Border removal
  - Contrast enhancement (CLAHE)
- âœ… Line and word segmentation
- âœ… Layout-aware OCR with confidence scores

### 3. Unicode Normalization
- âœ… Auto-detection of input format (Devanagari vs romanized)
- âœ… Romanization scheme support:
  - IAST
  - ITRANS
  - Harvard-Kyoto
  - Velthuis
  - WX
  - SLP1
- âœ… Unicode normalization (NFC/NFKC)
- âœ… Character fixing (matras, visarga, anusvara)
- âœ… Word spacing correction
- âœ… Sentence segmentation
- âœ… Bidirectional transliteration (Devanagari â†” Roman)

### 4. Translation
- âœ… Google Translate integration
- âœ… IndicTrans2 support (HuggingFace)
- âœ… mBART multilingual model fallback
- âœ… Ensemble translation
- âœ… Context-aware translation
- âœ… Batch sentence translation
- âœ… Back-translation for quality checking

### 5. Training Infrastructure
- âœ… Complete training loop with validation
- âœ… Learning rate scheduling (Cosine Annealing)
- âœ… Gradient clipping
- âœ… Automatic checkpointing
- âœ… Best model saving (by PSNR and loss)
- âœ… Training history logging (JSON)
- âœ… Weights & Biases integration
- âœ… TensorBoard support

### 6. Metrics & Evaluation
- âœ… PSNR (Peak Signal-to-Noise Ratio)
- âœ… SSIM (Structural Similarity Index)
- âœ… LPIPS (Learned Perceptual Image Patch Similarity)
- âœ… MSE & MAE
- âœ… Running metrics for training
- âœ… Batch metric calculation

### 7. Data Management
- âœ… Synthetic degradation generator
- âœ… Data augmentation (flip, rotate, crop)
- âœ… Flexible dataset loader
- âœ… Multi-worker data loading
- âœ… Support for various image formats
- âœ… Dataset downloader script

### 8. Visualization
- âœ… Original vs restored comparison
- âœ… Pipeline stage visualization
- âœ… Training history plots
- âœ… Attention map visualization
- âœ… Comprehensive demo figures
- âœ… Export to multiple formats

### 9. Pipeline Integration
- âœ… End-to-end processing function
- âœ… Configurable components
- âœ… Intermediate result saving
- âœ… Batch processing support
- âœ… JSON/text output export
- âœ… Error handling and logging

---

## ğŸ“ Project Structure

```
EL-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original manuscript images
â”‚   â”œâ”€â”€ processed/        # Processed images
â”‚   â””â”€â”€ datasets/         # Downloaded datasets
â”‚       â””â”€â”€ samples/      # Sample images
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vit_restorer.py   # Vision Transformer model
â”‚   â””â”€â”€ checkpoints/      # Model checkpoints
â”œâ”€â”€ ocr/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocess.py     # Image preprocessing
â”‚   â””â”€â”€ run_ocr.py        # OCR engines
â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unicode_normalizer.py  # Text normalization
â”‚   â””â”€â”€ translation.py    # Sanskritâ†’English translation
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset_loader.py # Dataset utilities
â”‚   â”œâ”€â”€ metrics.py        # Quality metrics
â”‚   â””â”€â”€ visualization.py  # Plotting functions
â”œâ”€â”€ output/               # Processing results
â”œâ”€â”€ logs/                 # Training logs
â”œâ”€â”€ main.py               # Full pipeline
â”œâ”€â”€ train.py              # Model training
â”œâ”€â”€ inference.py          # Inference script
â”œâ”€â”€ dataset_downloader.py # Dataset setup
â”œâ”€â”€ test_setup.py         # Installation test
â”œâ”€â”€ setup.sh              # Setup script
â”œâ”€â”€ demo.ipynb            # Jupyter demo
â”œâ”€â”€ config.yaml           # Configuration
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ README.md             # Documentation
â”œâ”€â”€ LICENSE               # MIT License
â””â”€â”€ .gitignore           # Git ignore rules
```

---

## ğŸš€ Quick Start

### 1. Setup

```bash
# Clone/navigate to project
cd EL-project

# Run setup script
./setup.sh

# Or manual setup:
pip install -r requirements.txt
sudo apt-get install tesseract-ocr tesseract-ocr-san
```

### 2. Prepare Data

```bash
# Download/setup datasets
python dataset_downloader.py

# Add your manuscript images to data/raw/
```

### 3. Train Model

```bash
python train.py --train_dir data/raw --epochs 100 --batch_size 16
```

### 4. Process Manuscripts

```bash
# Single image
python main.py --image_path data/raw/manuscript.jpg

# With trained model
python main.py --image_path data/raw/manuscript.jpg \
               --restoration_model checkpoints/best_psnr.pth

# Inference only
python inference.py --input data/raw/ \
                   --output output/restored/ \
                   --checkpoint checkpoints/best_psnr.pth
```

### 5. Use Python API

```python
from main import process_manuscript

result = process_manuscript(
    image_path="data/raw/manuscript.jpg",
    restoration_model="checkpoints/best_psnr.pth",
    ocr_engine='tesseract',
    translation_method='google',
    save_output=True
)

print("Sanskrit:", result['ocr_text_cleaned'])
print("English:", result['translation'])
```

---

## ğŸ“Š Model Architectures

### ViT Restoration Model Sizes

| Size  | Embed Dim | Layers | Heads | Parameters |
|-------|-----------|--------|-------|------------|
| Tiny  | 192       | 12     | 3     | ~5M        |
| Small | 384       | 12     | 6     | ~22M       |
| Base  | 768       | 12     | 12    | ~86M       |
| Large | 1024      | 24     | 16    | ~307M      |

---

## ğŸ”§ Configuration

Edit `config.yaml` to customize:
- Model architecture
- Training hyperparameters
- OCR settings
- Translation method
- Output format

---

## ğŸ“ Usage Examples

### Training with Custom Settings

```bash
python train.py \
    --train_dir data/raw \
    --val_dir data/val \
    --model_size base \
    --epochs 100 \
    --batch_size 16 \
    --lr 1e-4 \
    --use_wandb
```

### Batch Processing

```python
from main import ManuscriptPipeline
from pathlib import Path

pipeline = ManuscriptPipeline(
    restoration_model_path='checkpoints/best_psnr.pth',
    ocr_engine='tesseract',
    translation_method='google'
)

for img_path in Path('data/raw').glob('*.jpg'):
    result = pipeline.process_manuscript(img_path)
    print(f"{img_path.name}: {result['translation']}")
```

### Custom OCR Only

```python
from ocr.run_ocr import SanskritOCR

ocr = SanskritOCR(engine='tesseract')
text = ocr.extract_text('manuscript.jpg', lang='san')
print(text)
```

### Translation Only

```python
from nlp.translation import SanskritTranslator

translator = SanskritTranslator(method='google')
english = translator.translate("à¤°à¤¾à¤®à¤ƒ à¤µà¤¨à¤‚ à¤—à¤šà¥à¤›à¤¤à¤¿")
print(english)
```

---

## ğŸ“ˆ Performance Metrics

The restoration model is evaluated using:
- **PSNR**: Measures pixel-level accuracy
- **SSIM**: Measures structural similarity
- **LPIPS**: Measures perceptual quality

Typical results after training:
- PSNR: 28-35 dB
- SSIM: 0.85-0.95
- LPIPS: 0.05-0.15

---

## ğŸŒ Dataset Sources

1. **e-Granthalaya**: https://gretil.sub.uni-goettingen.de/
2. **Sanskrit Documents**: https://sanskritdocuments.org/
3. **Digital Library of India**: https://dli.sanskritdictionary.com/
4. **Kaggle Devanagari**: https://www.kaggle.com/search?q=devanagari
5. **IIIT Handwritten**: https://cvit.iiit.ac.in/

---

## ğŸ”¬ Technical Details

### Synthetic Degradation

Automatically generates training pairs by applying:
- Gaussian noise
- Motion/Gaussian blur
- Contrast reduction (fading)
- Salt & pepper noise
- Color shifting (aging)
- Random stains/spots

### OCR Preprocessing

Multi-stage pipeline:
1. Grayscale conversion
2. Noise reduction
3. Skew correction
4. Binarization (adaptive/Otsu/Sauvola)
5. Border removal
6. Contrast enhancement

### Unicode Normalization

Handles:
- Multiple romanization schemes (IAST, ITRANS, etc.)
- Unicode normalization (NFC/NFKC)
- Character corrections (matras, visarga, anusvara)
- Word spacing fixes
- Sentence segmentation

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Fine-tuned TrOCR models for Devanagari
- Custom IndicTrans2 training
- Additional augmentation strategies
- Pre-trained model weights
- Benchmark datasets

---

## ğŸ“„ License

MIT License - See LICENSE file

---

## ğŸ™ Acknowledgments

- PyTorch Team
- HuggingFace Transformers
- Tesseract OCR
- Indic NLP Library
- AI4Bharat (IndicTrans2)
- Vision Transformer (ViT) authors

---

## ğŸ“ Support

For issues or questions:
1. Check the documentation
2. Run `python test_setup.py` to verify installation
3. Review demo.ipynb for examples
4. Check existing issues on GitHub

---

## ğŸ¯ Roadmap

- [ ] Pre-trained model weights
- [ ] Web interface (Gradio/Streamlit)
- [ ] Docker container
- [ ] API service
- [ ] Mobile app
- [ ] Real-time processing
- [ ] Multi-language support (beyond Sanskrit)

---

**Built with â¤ï¸ for preserving ancient Sanskrit manuscripts**

