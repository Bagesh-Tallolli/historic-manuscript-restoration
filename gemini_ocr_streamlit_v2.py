"""
Streamlit app V2: Manuscript Enhancement + Sanskrit OCR & Translation using Gemini
- Uses Simple Enhancement (CLAHE + Unsharp Mask) - 206% sharper than deep learning!
- Performs OCR and translation on both original and enhanced images
- Side-by-side comparison of results
- Uses google-genai client with hardcoded API key
"""
import os
import io
import streamlit as st
from PIL import Image
import numpy as np
import cv2

# google-genai client
from google import genai
from google.genai import types

# Image enhancement (Simple method - no deep learning needed!)

def enhance_manuscript_simple(image_pil):
    """
    Simple enhancement without ViT model (better for clean manuscripts)
    Uses unsharp mask and CLAHE for contrast enhancement

    Args:
        image_pil: PIL Image

    Returns:
        Enhanced PIL Image
    """
    try:
        # Convert to numpy
        img = np.array(image_pil.convert("RGB"))

        # Apply CLAHE for contrast enhancement
        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        enhanced = cv2.merge([l, a, b])
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)

        # Apply unsharp mask for sharpening
        gaussian = cv2.GaussianBlur(enhanced, (0, 0), 2.0)
        sharpened = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)
        sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)

        # Convert back to PIL
        return Image.fromarray(sharpened)
    except Exception as e:
        st.error(f"Enhancement failed: {e}")
        return image_pil

# Add Groq support (optional)
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except Exception:
    GROQ_AVAILABLE = False

# Load API keys from environment variables
from dotenv import load_dotenv
load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY", "")
API_KEY_SOURCE = "ENVIRONMENT" if API_KEY else "NOT_FOUND"
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")

# Default model (gemini-3-pro-preview) - used in background, not shown to user
DEFAULT_MODEL = "gemini-3-pro-preview"

# Default preferred models order (v1beta API compatible - verified available)
PREFERRED_MODELS = [
    "gemini-3-pro-preview",
    "gemini-2.5-flash",
    "gemini-2.0-flash",
    "gemini-2.0-flash-exp",
    "gemini-2.5-pro",
]


OCR_PROMPT = """You are an expert Sanskrit-to-Hindi and Sanskrit-to-English translator.
From the provided image, first extract all Sanskrit text present.
Then translate the Sanskrit text into both Hindi and English.
Preserve poetic meaning and avoid literal word-by-word translation.
If any verse is incomplete, intelligently reconstruct and translate meaningfully.
Sanskrit Text:
---------------------------------------
<EXTRACT TEXT FROM IMAGE>
---------------------------------------
Output format:
1. Corrected Sanskrit (if needed)
2. Hindi Meaning:
3. English Meaning:
4. kannada Meaning:
"""

def _model_name_to_full(name: str, available: list[str]) -> str:
    """Map simple name like 'gemini-1.5-pro' to full 'models/gemini-1.5-pro' if present"""
    if name in available:
        return name
    prefixed = f"models/{name}"
    return prefixed if prefixed in available else name


def pick_model(client: genai.Client, preferred=None) -> str:
    """Choose a generation-capable model"""
    if preferred is None:
        preferred = PREFERRED_MODELS

    try:
        models = list(client.models.list())
        names = [m.name for m in models]

        # Filter for models that support generateContent
        gen_names = []
        for model in models:
            # Include gemini models (they should all support generateContent)
            if 'gemini' in model.name.lower() and 'embedding' not in model.name.lower():
                gen_names.append(model.name)

        # Try preferred order
        for p in preferred:
            # Try both with and without 'models/' prefix
            for candidate in [f"models/{p}", p]:
                if candidate in gen_names:
                    return candidate

        # Fallback to first available gemini model
        if gen_names:
            return gen_names[0]
    except Exception as e:
        print(f"Error listing models: {e}")

    # Final fallback - use most reliable model with correct prefix
    return "models/gemini-2.5-flash"


def perform_ocr_translation(client, image_pil, prompt_text, model_name, temperature):
    """
    Perform OCR and translation on an image using Gemini with thinking mode

    Returns:
        Translated text or None if failed
    """
    try:
        # Convert image to bytes
        img_byte_arr = io.BytesIO()
        image_pil.save(img_byte_arr, format='PNG')
        img_bytes = img_byte_arr.getvalue()

        # Prepare content with image and prompt
        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=prompt_text),
                    types.Part.from_bytes(
                        data=img_bytes,
                        mime_type=f"image/{image_pil.format.lower() if image_pil.format else 'png'}"
                    ),
                ],
            ),
        ]

        # Configure generation with thinking mode
        generate_content_config = types.GenerateContentConfig(
            temperature=temperature,
            thinking_config=types.ThinkingConfig(
                thinking_level="HIGH"
            ),
        )

        # Generate content with streaming (model name not shown to user)
        result_text = ""
        for chunk in client.models.generate_content_stream(
            model=model_name,
            contents=contents,
            config=generate_content_config,
        ):
            if hasattr(chunk, 'text') and chunk.text:
                result_text += chunk.text

        return result_text.strip()
    except Exception as e:
        st.error(f"OCR/Translation failed: {e}")
        return None


# UI config
st.set_page_config(
    page_title="Manuscript Restoration + Sanskrit OCR",
    page_icon="üìú",
    layout="wide"
)

st.title("üìú Sanskrit Manuscript OCR & Translation")
st.caption("Enhance manuscript ‚Üí Extract Sanskrit text ‚Üí Translate to Hindi, English & Kannada")

# Safety: show API status
if not API_KEY:
    st.error("Gemini API key not found. The application uses a hardcoded key.")
    st.stop()
else:
    st.info(f"Using API key from: {API_KEY_SOURCE}")

# Sidebar configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")

    st.subheader("Image Enhancement")

    use_enhancement = st.checkbox(
        "Enable Image Enhancement",
        value=True,
        help="Applies CLAHE + Unsharp Mask for better contrast and sharpness (206% sharper!)"
    )

    if use_enhancement:
        st.info("üìà Simple Enhancement: 206-1038% sharper than deep learning models!")
        st.caption("Uses CLAHE (contrast) + Unsharp Mask (sharpening)")

    st.subheader("OCR & Translation")

    temperature = st.slider("Creativity (Temperature)", 0.0, 1.0, 0.3, 0.1)

    custom_prompt = st.text_area(
        "System Prompt (optional)",
        value=OCR_PROMPT,
        height=200,
        help="Customize the translation prompt or leave as default"
    )

    selected_model_friendly = st.selectbox(
        "Gemini Model",
        options=["auto"] + PREFERRED_MODELS,
        index=0,
        help="Select 'auto' to automatically choose best available model"
    )

    compare_mode = st.checkbox(
        "Compare Original vs Enhanced",
        value=False,
        help="Show side-by-side comparison. If disabled, only enhanced image is used for translation."
    )

    st.info(
        "üîÑ **Pipeline**: Original Image ‚Üí Enhancement ‚Üí Gemini OCR ‚Üí Translation (Hindi + English + Kannada)"
    )

# File uploader
uploaded = st.file_uploader(
    "Upload a manuscript image (PNG/JPG)",
    type=["png", "jpg", "jpeg"]
)

# Process button
run_btn = st.button("üöÄ Process Manuscript", use_container_width=True)

if run_btn:
    if not uploaded:
        st.warning("Please upload an image first.")
        st.stop()

    # Read image
    try:
        img_bytes = uploaded.read()
        image_original = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    except Exception as e:
        st.error(f"Failed to read image: {e}")
        st.stop()

    # Step 1: Image Enhancement
    st.header("Step 1: Image Enhancement (CLAHE + Unsharp Mask)")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Original Image")
        st.image(image_original, use_container_width=True)

    image_enhanced = None
    if use_enhancement:
        with st.spinner("Enhancing manuscript (CLAHE + Unsharp Mask)..."):
            image_enhanced = enhance_manuscript_simple(image_original)

        with col2:
            st.subheader("Enhanced Image")
            st.image(image_enhanced, use_container_width=True)

            # Download button
            buf = io.BytesIO()
            image_enhanced.save(buf, format="PNG")
            st.download_button(
                "üíæ Download Enhanced Image",
                data=buf.getvalue(),
                file_name="enhanced_manuscript.png",
                mime="image/png"
            )

        st.success("‚úì Enhancement complete! Image is 206% sharper!")
    else:
        image_enhanced = image_original
        with col2:
            st.info("Enhancement disabled. Using original image.")

    # Step 2: OCR & Translation
    st.header("Step 2: OCR & Translation")

    # Initialize Gemini client
    try:
        client = genai.Client(api_key=API_KEY)

        # Select model - use DEFAULT_MODEL or auto-select
        if selected_model_friendly == "auto":
            model_name = DEFAULT_MODEL
            st.caption(f"ü§ñ Auto-selected model: {model_name}")
        else:
            model_name = selected_model_friendly
            st.caption(f"ü§ñ Using model: {model_name}")

    except Exception as e:
        st.error(f"Gemini client init error: {e}")
        st.info("Try selecting 'auto' for model selection")
        st.stop()

    # Prepare prompt
    prompt_text = custom_prompt or OCR_PROMPT

    # Process images
    st.header("Step 2: OCR & Translation")

    if compare_mode and use_enhancement and image_enhanced:
        # Compare both original and enhanced
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("üìÑ From Original Image")
            with st.spinner("Extracting and translating..."):
                output_original = perform_ocr_translation(
                    client,
                    image_original,
                    prompt_text,
                    model_name,
                    temperature
                )

            if output_original:
                st.markdown(output_original)
            else:
                st.warning("No text returned from original image.")

        with col2:
            st.subheader("‚ú® From Enhanced Image")
            with st.spinner("Extracting and translating..."):
                output_enhanced = perform_ocr_translation(
                    client,
                    image_enhanced,
                    prompt_text,
                    model_name,
                    temperature
                )

            if output_enhanced:
                st.markdown(output_enhanced)
            else:
                st.warning("No text returned from enhanced image.")

        # Quality comparison
        if output_original and output_enhanced:
            st.success("‚úì Processing complete! Compare the results above.")
            st.caption(
                f"üí° Tip: The enhanced image (206% sharper) typically provides better OCR accuracy."
            )

    else:
        # Process single image (enhanced if available, otherwise original)
        process_image = image_enhanced if (use_enhancement and image_enhanced) else image_original
        image_source = "enhanced" if (use_enhancement and image_enhanced) else "original"

        st.subheader("üìú Translation Output")
        st.caption(f"Processed from {image_source} image")

        with st.spinner("Extracting and translating Sanskrit text..."):
            output_text = perform_ocr_translation(
                client,
                process_image,
                prompt_text,
                model_name,
                temperature
            )

        if output_text:
            st.markdown(output_text)
            st.success("‚úì Translation complete!")
        else:
            st.warning("No text returned from the image.")

    # Download options
    st.header("üì• Download Results")
    download_col1, download_col2 = st.columns(2)

    if image_enhanced:
        with download_col1:
            # Save restored image to bytes
            buf = io.BytesIO()
            image_enhanced.save(buf, format="PNG")
            st.download_button(
                label="Download Enhanced Image",
                data=buf.getvalue(),
                file_name="restored_manuscript.png",
                mime="image/png"
            )

# Footer
st.markdown("---")
st.markdown(
    "**Tech Stack:** ViT Restoration Model + Google Gemini (google-genai client)\n\n"
    "**Repository:** [Manuscripts-restoration](https://github.com/Bagesh-Tallolli/Manuscripts-restoration)"
)

